---
title: "Exploratory Analysis of Keywords in Forums on Dissociation"
output: github_document
date: '2022-03-25'
---
##### Description of raw data:

 * Webscraped using PRAW, Reddit's API
 * From forum about depersonalization/derealization.
 * Contains post title, post content, post date
 * Data date range: 2022-03-01 to 2022-03-27
 * Ideas: compare topics to DSM5 symptoms

```{r echo = FALSE, message= FALSE}
library(dplyr)
data <- read.csv("dataset/dpdr_precov.csv")
data2 <- read.csv("dataset/dpdr_midcov.csv")
data3 <- read.csv("dataset/dpdr_postcov.csv")
text_df <- tibble(data[4])
text_df2 <- tibble(data2[4])
text_df3 <- tibble(data3[4])
```


#### Most commonly used words:

```{r echo = FALSE, message = FALSE}
#most commonly used words
library(dplyr)
library(ggplot2)
library(tidytext)
library(stringr)

text_df3 %>%
  unnest_tokens(word,selftext) %>%
  count(word, sort = TRUE) %>%
  filter(!word %in% stop_words$word,
         !word %in% str_remove_all(stop_words$word, "'"),
          str_detect(word,"[a-z]")) %>%
  filter(n > 100) %>%
  mutate(word = reorder(word,n)) %>%
  ggplot(aes(n,word)) +
  geom_col() +
  labs(y = NULL)

#wordcloud
library(wordcloud)

text_df3 %>%
  unnest_tokens(word,selftext) %>%
  anti_join(stop_words) %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 100))
```

#### Most common positive and negative words:
```{r echo = FALSE, message = FALSE}
library(dplyr)
library(stringr)
library(tidyr)
library(ggplot2)
library(tidyr)
library(tidytext)
# most common positive and negative words
bing_word_counts <- text_df3 %>%
  unnest_tokens(word,selftext) %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()

bing_word_counts %>%
  group_by(sentiment) %>%
  slice_max(n, n = 10) %>% 
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(x = "Contribution to sentiment",
       y = NULL)
```

#### Relationships between words: n-grams and correlations

##### Visualizing a network of bigrams:
```{r  echo = FALSE, message = FALSE}
#bigrams
library(dplyr)
library(tidyr)
library(tidytext)
library(ggplot2)
library(igraph)
library(ggraph)

count_bigrams <- function(dataset) {
  dataset %>%
    unnest_tokens(bigram, selftext, token = "ngrams", n = 2) %>%
    separate(bigram, c("word1", "word2"), sep = " ") %>%
    filter(!word1 %in% stop_words$word,
           !word2 %in% stop_words$word) %>%
    count(word1, word2, sort = TRUE)
}

visualize_bigrams <- function(bigrams) {
  set.seed(2016)
  a <- grid::arrow(type = "closed", length = unit(.15, "inches"))
  
  bigrams %>%
    graph_from_data_frame() %>%
    ggraph(layout = "fr") +
    geom_edge_link(aes(edge_alpha = n), show.legend = FALSE, arrow = a) +
    geom_node_point(color = "lightblue", size = 5) +
    geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
    theme_void()
}
library(stringr)

kjv_bigrams <- text_df3 %>%
  count_bigrams()

# filter out rare combinations, as well as digits
kjv_bigrams %>%
  filter(n > 40,
         !str_detect(word1, "\\d"),
         !str_detect(word2, "\\d")) %>%
  visualize_bigrams()
```

##### Centrality of Words
```{r echo=FALSE, message=FALSE}
library(tidygraph)
library(ggrepel)
library(ggplot2)
bigram_graph <- text_df3 %>%
  unnest_tokens(bigram ,selftext, token = "ngrams", n = 2) %>%
  separate(bigram, c("word1", "word2"), sep = " " ) %>%
  anti_join(stop_words, by = c("word1" = "word")) %>%
  anti_join(stop_words, by = c("word2" = "word")) %>%
  count(word1, word2, sort = TRUE) %>%
  select(word1, word2, n) %>%
  filter(n>2) %>%
  as_tbl_graph()

bigram_graph %>%
  mutate(centrality = centrality_degree()) %>% 
    ggraph(layout = 'kk') + 
    geom_edge_link() + 
    geom_node_point(aes(size = centrality, color = centrality)) + 
    geom_node_text(aes(label = name), repel = TRUE) +
    theme_graph() +
   theme(legend.position = "none") 

```


